Tensorflow:
	1. tf.estimator: High level Tensorflow Api.


Pandas:
	1. It is a column-oriented data analysis API. 
	2. Primary data structures in pandas are implemented as two classes:
		a). DataFrame is a relational data table with rows and named columns. DataFrame objects can be created by passing a dict mapping string column names to their respective Series. If the Series don't match in length, missing values are filled with special NA/NaN values.

			city_names = pd.Series(['San Francisco', 'San Jose', 'Sacramento'])
			population = pd.Series([852469, 1015785, 485199])
			pd.DataFrame({ 'City name': city_names, 'Population': population })

		But most of the time, you load an entire file into a DataFrame. The following example loads a file with California housing data
			
			california_housing_dataframe = pd.read_csv("https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv", sep=",")
			california_housing_dataframe.describe()

		DataFrame.head, which displays the first few records of a DataFrame:
			california_housing_dataframe.head()

		Another powerful feature of pandas is graphing. For example, DataFrame.hist lets you quickly study the distribution of values in a column:
			california_housing_dataframe.hist('housing_median_age')


		b). Series is a single column. A DataFrame contains one or more Series and a name for each Series.
			pd.Series(['San Francisco', 'San Jose', 'Sacramento'])

Steps to estimate value using tenserflow:
1. Define Features and Configure Features Columns:
	In order to import training data into tenserflow , we need to specify the type of data each features contain.
	
	In tenserflow, we indicate a feature's data type using a contruct called "feature column". Feature column store only description of feature data not the feature data itself.
		feature_columns = [tf.feature_column.numeric_column("total_rooms")]
		my_feature = california_housing_dataframe[["total_rooms"]]

2. Define target:
	Next we have to define our target which is median_house_value. 
		targets = california_housing_dataframe["median_house_value"]

3. Configure the LinearRegressor:
	Configure the linear regressor model using LinearRegressor. Train this model using GradientDescentOptimizer, which implements Mini-Batch Stochastic Gradient Descent(SGD). 
	
	Learning rate arguments control the size of gradient step.

	To be safe, gradient clipping is applied to optimizer via clip_gradients_by_norm. Gradient clipping ensures that magnitude of gradients do not become too large during training which can cause gradient descent to fail.

		my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.0000001)
		my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)

		linear_regressor = tf.estimator.LinearRegressor(
    		feature_columns=feature_columns,
    		optimizer=my_optimizer
		)

4. Define Input function:
	def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):
    	"""Trains a linear regression model of one feature.
  
		    Args:
		      features: pandas DataFrame of features
		      targets: pandas DataFrame of targets
		      batch_size: Size of batches to be passed to the model
		      shuffle: True or False. Whether to shuffle the data.
		      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely
		    Returns:
		      Tuple of (features, labels) for next data batch
    	"""
  
	    # Convert pandas data into a dict of np arrays.
	    features = {key:np.array(value) for key,value in dict(features).items()}                                           
	 
	    # Construct a dataset, and configure batching/repeating.
	    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit
	    ds = ds.batch(batch_size).repeat(num_epochs)
	    
	    # Shuffle the data, if specified.
	    if shuffle:
	      ds = ds.shuffle(buffer_size=10000)
	    
	    # Return the next batch of data.
	    features, labels = ds.make_one_shot_iterator().get_next()
	    return features, labels

5. Train the Model:
	_ = linear_regressor.train(
    	input_fn = lambda:my_input_fn(my_feature, targets),
    	steps=100
	)

6. Evaluate the Model:
	prediction_input_fn =lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)
	predictions = linear_regressor.predict(input_fn=prediction_input_fn)

	# Format predictions as a NumPy array, so we can calculate error metrics.
	predictions = np.array([item['predictions'][0] for item in predictions])

	# Print Mean Squared Error and Root Mean Squared Error.
	mean_squared_error = metrics.mean_squared_error(predictions, targets)
	root_mean_squared_error = math.sqrt(mean_squared_error)
	print("Mean Squared Error (on training data): %0.3f" % mean_squared_error)
	print("Root Mean Squared Error (on training data): %0.3f" % root_mean_squared_error)